# Sprint 11 Module 11.2 Guided Project

1. Train a Classifier Model: We will use the famous Iris dataset from Scikit-Learn and train a classifier model. For simplicity, let's use a Random Forest classifier. 
2. Serialize Model with joblib: After training the model, we will serialize it (save it to a file) using joblib so that it can be loaded and used later. 
3. Integrate the Model into a simple FastAPI app: We will write the code for a simple FastAPI app which will use the saved model to make predictions.

#### File: `validate.py`
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Load iris dataset
iris = load_iris()
X, y = iris.data, iris.target

# Split the dataset into a training set and a test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Create a RandomForestClassifier and train it on the training data
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# Predict the labels for the test data
y_pred = clf.predict(X_test)

# Compute the accuracy of the model
print(accuracy_score(y_test, y_pred))

```

```bash
python -m validate
```

The accuracy of the model on the test data should be 1.0 or close to it, which means it made correct predictions for all or nearly all test instances. This is due to the simplicity and small size of the Iris dataset. Feel free to use your own data!

Let's move on to the second step by retraining and serializing our model. This will allow us to save the model to a file and load it later when we want to make predictions. Notice we're now using all the data we have for production. This assumes our model has passed the validation stage, and now we can use all the data to build the best model possible for deployment.

#### File: `train.py`
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from joblib import dump

# Load iris dataset
iris = load_iris()
X, y = iris.data, iris.target

# Create a RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100, random_state=42)

# Train it on all the data we have
clf.fit(X, y)

# Save the model to a file
dump(clf, 'iris_classifier.joblib')

```

Once the `train.py` file has been executed the model will be serialized and saved to the file `iris_classifier.joblib`.

```bash
python -m train
```

Now let's write the code for a simple FastAPI app that can use this model to make predictions. Here is the basic code structure for a FastAPI app that uses our saved model:

File: `main.py`
```python
from fastapi import FastAPI
from joblib import load

# Load the pre-trained model
model = load('iris_classifier.joblib')

# Initialize the FastAPI app
app = FastAPI(
    title="Iris Classifier",
    docs_url="/"
)

# Define the prediction endpoint
@app.post('/predict/')
def predict_species(sepal_length: float, sepal_width: float, petal_length: float, petal_width: float):
    # Extract data from the request
    data = [sepal_length, sepal_width, petal_length, petal_width]

    # Make a prediction
    prediction = model.predict([data])

    # Map prediction to the corresponding iris species
    iris_species = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}
    predicted_species = iris_species[prediction[0]]

    # Return the prediction
    return {'predicted_species': predicted_species}

```

In this code, we define a FastAPI app with a single POST endpoint (/predict/). This endpoint expects data in the format defined by the IrisSpecies Pydantic model (four float values), makes a prediction using the pre-trained model, and returns the predicted iris species.

Remember to place the iris_classifier.joblib file in the same directory as your FastAPI Python script, or adjust the file path in the load('iris_classifier.joblib') line accordingly. We can run this FastAPI app using a tool like Uvicorn or Hypercorn.

```bash
uvicorn main:app
```

Run the server and make some predictions.
