## Guided Project - CUDA Powered Stable Diffusion API

### Implementing Stable Diffusion with CUDA Support

There are additional dependencies to use CUDA.
1. CUDA enabled GPU (nVidia)
2. [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
3. Linux or Windows 10+ (sorry macOS!)
4. CUDA enabled pytorch and associated libraries (see requirements-cuda.txt)

To implement Stable Diffusion in our FastAPI app, we'll use the `CudaImageKit` class that we've defined. This class uses the `DiffusionPipeline` from the `diffusers` package to perform the Stable Diffusion process.

File: `requirements-cuda.txt`

```requirements.txt
--extra-index-url https://download.pytorch.org/whl/cu118

accelerate
certifi
diffusers
fastapi
pydantic
pymongo[srv]
python-dotenv
python-multipart
torch
transformers
uvicorn[standard]
```

```bash
pip install -r requirements-cuda.txt
```

File: `main.py`

```python
import os
from uuid import uuid4

import torch
from fastapi import FastAPI
from fastapi.responses import FileResponse
from diffusers import DiffusionPipeline

app = FastAPI()


class CudaImageKit:
    directory = "jobs"
    if not os.path.exists(directory):
        os.makedirs(directory)
    device = "cuda" if torch.cuda.is_available() else "cpu"

    def __call__(self,
                 job_id: str,
                 prompt: str,
                 negative_prompt: str,
                 model_id: str,
                 height: int,
                 width: int,
                 guidance_scale: float,
                 num_inference_steps: int):
        self.pipe = DiffusionPipeline.from_pretrained(model_id).to(self.device)
        image, *_ = self.pipe(
            prompt=prompt,
            height=height,
            width=width,
            guidance_scale=guidance_scale,
            num_inference_steps=num_inference_steps,
        ).images
        image.save(os.path.join(self.directory, f"{job_id}.png"))


cuda_image_kit = CudaImageKit()


@app.post("/jobs")
async def post_job(prompt: str,
                   negative_prompt: str,
                   model_id: str = "stabilityai/stable-diffusion-2-1",
                   height: int = 512,
                   width: int = 512,
                   guidance_scale: float = 7.5,
                   num_inference_steps: int = 100):
    job_id = uuid4()
    job_details = {
        "job_id": job_id,
        "prompt": prompt,
        "negative_prompt": negative_prompt,
        "model_id": model_id,
        "height": height,
        "width": width,
        "guidance_scale": guidance_scale,
        "num_inference_steps": num_inference_steps
    }
    cuda_image_kit(**job_details)
    filepath = os.path.join("jobs", f"{job_id}.png")
    return FileResponse(filepath, media_type="image/png")

```

```bash
uvicorn main:app
```
The `CudaImageKit` class has been designed to dynamically detect if CUDA is available and to use it if possible. This means that if you're running this on a machine with a CUDA-enabled GPU, the image generation process will be significantly faster.
